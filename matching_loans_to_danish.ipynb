{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18bd01c2-3719-410e-b880-c964339774bd",
   "metadata": {},
   "source": [
    "## Installing packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13f32aef-66c5-4e10-8151-390f80a7795e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.12/site-packages (2.2.3)\n",
      "Collecting openpyxl\n",
      "  Downloading openpyxl-3.1.5-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /opt/conda/lib/python3.12/site-packages (from pandas) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.12/site-packages (from pandas) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.12/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.12/site-packages (from pandas) (2024.2)\n",
      "Collecting et-xmlfile (from openpyxl)\n",
      "  Downloading et_xmlfile-2.0.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Downloading openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n",
      "Downloading et_xmlfile-2.0.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: et-xmlfile, openpyxl\n",
      "Successfully installed et-xmlfile-2.0.0 openpyxl-3.1.5\n",
      "Collecting pyarrow\n",
      "  Downloading pyarrow-18.1.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "Downloading pyarrow-18.1.0-cp312-cp312-manylinux_2_28_x86_64.whl (40.1 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m40.1/40.1 MB\u001b[0m \u001b[31m55.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pyarrow\n",
      "Successfully installed pyarrow-18.1.0\n",
      "Collecting nltk\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.12/site-packages (from nltk) (8.1.7)\n",
      "Collecting joblib (from nltk)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting regex>=2021.8.3 (from nltk)\n",
      "  Downloading regex-2024.11.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.12/site-packages (from nltk) (4.67.0)\n",
      "Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading regex-2024.11.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (796 kB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m796.9/796.9 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Installing collected packages: regex, joblib, nltk\n",
      "Successfully installed joblib-1.4.2 nltk-3.9.1 regex-2024.11.6\n"
     ]
    }
   ],
   "source": [
    "! pip install pandas openpyxl\n",
    "! pip install pyarrow\n",
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e96e07c6-8f55-4283-8f39-061b9d203622",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64044c4f-9eee-4d7f-a427-396e8c2a5ace",
   "metadata": {},
   "source": [
    "## Importing the files i prepared in the other notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "891735d4-e5dd-4d07-85ef-ab7930e7cd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the first CSV file into a DataFrame\n",
    "tweets = pd.read_csv('tweets.csv')\n",
    "\n",
    "# Load the second CSV file into a DataFrame\n",
    "selected_loan_types = pd.read_csv('selected_loan_types.csv')\n",
    "\n",
    "unadapted_borrowings = pd.read_csv('unadapted_borrowings.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f8a20b-56a3-46ef-af77-8370d131ab04",
   "metadata": {},
   "source": [
    "# Moving on to finding anglisiscms in a text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c85da3e-bcd9-4ef3-9dde-c10c69bc4378",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparing th eloans \n",
    "words_to_remove = {'e', 'I', 'm', 'k', 'b', 'a', 's', 'i', ',', 'en', 'for', 'og', 'de', 'af', 'et', 'man', 'her', 'da', 'over', 'end', 'have', 'mod', 'dig', 'alt', 'gang', 'to', 'igen', 'under', 'store', 'folk', 'g√•', 'dog'}\n",
    "\n",
    "# Ensure we are working with a copy\n",
    "selected_loan_types = selected_loan_types.copy()\n",
    "\n",
    "# 'Domestic Set' column\n",
    "selected_loan_types.loc[:, 'Domestic Set'] = selected_loan_types['Domestic form'].apply(\n",
    "    lambda x: set(str(x).split()) if isinstance(x, str) else set()\n",
    ")\n",
    "\n",
    "# Preprocess `Domestic` column to create sets of words for easier matching\n",
    "# Handle NaN or non-string values\n",
    "\n",
    "combined_loan_types = set().union(*selected_loan_types['Domestic Set'])\n",
    "\n",
    "# Assuming combined_loan_types is a set\n",
    "combined_loan_types = {item.lower() for item in combined_loan_types}\n",
    "\n",
    "# Remove unwanted words from the combined_loan_types set\n",
    "combined_loan_types -= {word.lower() for word in words_to_remove}\n",
    "\n",
    "# Now combined_loan_types has the filtered words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19eec555-9150-41f3-af1a-90e38e9f179c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   text  \\\n",
      "0                     35-√•rig mand erkender drab [LINK]   \n",
      "1     BILLEDSERIE: Hjerteforeningens lokalkomite man...   \n",
      "2       Det m√• jo v√¶re fraregnet #LordBendtner üòâ [LINK]   \n",
      "3     Det er s√• godt, @USER! Psykiatriske disgnoser ...   \n",
      "4     N√∏ddesbos h√•nd i Herning-rundk√∏rsel: Jeg er en...   \n",
      "...                                                 ...   \n",
      "1042  @USER Jeg sp√∏rger bare, hvorfor d√©t er i orden...   \n",
      "1043                                    S√• ENIG! [LINK]   \n",
      "1044  @USER Men det var jo ret sjovt :) som ikke er ...   \n",
      "1045  DAT fejrer 30 √•r med fly Det er i dag 30 √•r si...   \n",
      "1046  Eriksen har en glimrende statistik mod City [L...   \n",
      "\n",
      "                                           Cleaned Text  \\\n",
      "0                     35-√•rig mand erkender drab [link]   \n",
      "1     billedserie: hjerteforeningens lokalkomite man...   \n",
      "2       det m√• jo v√¶re fraregnet #lordbendtner üòâ [link]   \n",
      "3     det er s√• godt, @user! psykiatriske disgnoser ...   \n",
      "4     n√∏ddesbos h√•nd i herning-rundk√∏rsel: jeg er en...   \n",
      "...                                                 ...   \n",
      "1042  @user jeg sp√∏rger bare, hvorfor d√©t er i orden...   \n",
      "1043                                    s√• enig! [link]   \n",
      "1044  @user men det var jo ret sjovt :) som ikke er ...   \n",
      "1045  dat fejrer 30 √•r med fly det er i dag 30 √•r si...   \n",
      "1046  eriksen har en glimrende statistik mod city [l...   \n",
      "\n",
      "                                                 Tokens  \n",
      "0                            35 √•rig mand erkender drab  \n",
      "1     billedserie hjerteforeningens lokalkomite mang...  \n",
      "2                 det m√• jo v√¶re fraregnet lordbendtner  \n",
      "3     det er s√• godt , ! psykiatriske disgnoser skal...  \n",
      "4     n√∏ddesbos h√•nd i herning rundk√∏rsel jeg er en ...  \n",
      "...                                                 ...  \n",
      "1042  jeg sp√∏rger bare , hvorfor d√©t er i orden , n√•...  \n",
      "1043                                          s√• enig !  \n",
      "1044  men det var jo ret sjovt ) som ikke er ond mod...  \n",
      "1045  dat fejrer 30 √•r med fly det er i dag 30 √•r si...  \n",
      "1046  eriksen har en glimrende statistik mod city pl...  \n",
      "\n",
      "[1047 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5acbefef-0126-4ce0-be00-72f2403ff516",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to match and calculate\n",
    "def find_matches(tokens, loan_types):\n",
    "    matching_words = []\n",
    "    matching_indices = []\n",
    "    for idx, word in enumerate(tokens):\n",
    "        if word in loan_types:\n",
    "            matching_words.append(word)\n",
    "            matching_indices.append(idx)  # Store index of the matching word\n",
    "    return matching_words, matching_indices, len(matching_words)\n",
    "\n",
    "# Handle cases where Tokens is not a string\n",
    "results = []\n",
    "\n",
    "for tokens in tweets['Tokens']:\n",
    "    # Check if tokens is a string; if not, convert to empty string\n",
    "    if isinstance(tokens, str):\n",
    "        tokens = tokens.lower().split()  # Lowercase and split by spaces\n",
    "    else:\n",
    "        tokens = []  # Treat non-strings (e.g., NaN or floats) as empty list\n",
    "\n",
    "    # Match tokens against combined_loan_types\n",
    "    matches, match_indices, count = find_matches(tokens, combined_loan_types)\n",
    "    results.append({'Matching Words': matches, 'Match Indices': match_indices, 'Count': count})\n",
    "\n",
    "# Add results to DataFrame\n",
    "tweets['matches'] = [result['Matching Words'] for result in results]\n",
    "tweets['match_indices'] = [result['Match Indices'] for result in results]\n",
    "tweets['match_count'] = [result['Count'] for result in results]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bbfbb5cb-a4cc-4fa8-9725-aafb78387918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   text  \\\n",
      "0                     35-√•rig mand erkender drab [LINK]   \n",
      "1     BILLEDSERIE: Hjerteforeningens lokalkomite man...   \n",
      "2       Det m√• jo v√¶re fraregnet #LordBendtner üòâ [LINK]   \n",
      "3     Det er s√• godt, @USER! Psykiatriske disgnoser ...   \n",
      "4     N√∏ddesbos h√•nd i Herning-rundk√∏rsel: Jeg er en...   \n",
      "...                                                 ...   \n",
      "1042  @USER Jeg sp√∏rger bare, hvorfor d√©t er i orden...   \n",
      "1043                                    S√• ENIG! [LINK]   \n",
      "1044  @USER Men det var jo ret sjovt :) som ikke er ...   \n",
      "1045  DAT fejrer 30 √•r med fly Det er i dag 30 √•r si...   \n",
      "1046  Eriksen har en glimrende statistik mod City [L...   \n",
      "\n",
      "                                           Cleaned Text  \\\n",
      "0                     35-√•rig mand erkender drab [link]   \n",
      "1     billedserie: hjerteforeningens lokalkomite man...   \n",
      "2       det m√• jo v√¶re fraregnet #lordbendtner üòâ [link]   \n",
      "3     det er s√• godt, @user! psykiatriske disgnoser ...   \n",
      "4     n√∏ddesbos h√•nd i herning-rundk√∏rsel: jeg er en...   \n",
      "...                                                 ...   \n",
      "1042  @user jeg sp√∏rger bare, hvorfor d√©t er i orden...   \n",
      "1043                                    s√• enig! [link]   \n",
      "1044  @user men det var jo ret sjovt :) som ikke er ...   \n",
      "1045  dat fejrer 30 √•r med fly det er i dag 30 √•r si...   \n",
      "1046  eriksen har en glimrende statistik mod city [l...   \n",
      "\n",
      "                                                 Tokens    matches  \\\n",
      "0                            35 √•rig mand erkender drab         []   \n",
      "1     billedserie hjerteforeningens lokalkomite mang...         []   \n",
      "2                 det m√• jo v√¶re fraregnet lordbendtner         []   \n",
      "3     det er s√• godt , ! psykiatriske disgnoser skal...         []   \n",
      "4     n√∏ddesbos h√•nd i herning rundk√∏rsel jeg er en ...         []   \n",
      "...                                                 ...        ...   \n",
      "1042  jeg sp√∏rger bare , hvorfor d√©t er i orden , n√•...  [podcast]   \n",
      "1043                                          s√• enig !         []   \n",
      "1044  men det var jo ret sjovt ) som ikke er ond mod...         []   \n",
      "1045  dat fejrer 30 √•r med fly det er i dag 30 √•r si...         []   \n",
      "1046  eriksen har en glimrende statistik mod city pl...     [city]   \n",
      "\n",
      "     match_indices  match_count  \n",
      "0               []            0  \n",
      "1               []            0  \n",
      "2               []            0  \n",
      "3               []            0  \n",
      "4               []            0  \n",
      "...            ...          ...  \n",
      "1042          [28]            1  \n",
      "1043            []            0  \n",
      "1044            []            0  \n",
      "1045            []            0  \n",
      "1046           [6]            1  \n",
      "\n",
      "[1047 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "print(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c4c9387-bf5c-4492-ae58-77cbde9c5dd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "580\n"
     ]
    }
   ],
   "source": [
    "total = tweets['match_count'].sum()\n",
    "\n",
    "\n",
    "\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1af48069-8ab0-48af-b142-7ed8a36088d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nice! now we have a list of marked enlgish loans we can run the models on#\n",
    "tweets.to_csv('combined_loan_types_annotation.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259a75e3-7bb6-4f9c-b8bb-ea9e494635bc",
   "metadata": {},
   "source": [
    "## Applying the code to only the direct borrowings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4aede08-3445-4550-8359-09632d663d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure we are working with a copy\n",
    "unadapted_borrowings = unadapted_borrowings.copy()\n",
    "\n",
    "# Safely create the 'Domestic Set' column\n",
    "unadapted_borrowings.loc[:, 'Domestic Set'] = unadapted_borrowings['Domestic form'].apply(\n",
    "    lambda x: set(str(x).split()) if isinstance(x, str) else set()\n",
    ")\n",
    "# Preprocess `Domestic` column to create sets of words for easier matching\n",
    "# Handle NaN or non-string values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba849aa6-cc4b-4401-881a-8662515ca3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "unadapted_borrowings = set().union(*unadapted_borrowings['Domestic Set'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d5ee4c1-ef32-4855-9f71-17823af91d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming combined_loan_types is a set\n",
    "unadapted_borrowings = {item.lower() for item in unadapted_borrowings}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce77dd32-00db-43ef-a4ca-f49b6572eacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to match and calculate\n",
    "def find_matches(tokens, loan_types):\n",
    "    matching_words = [word for word in tokens if word in loan_types]\n",
    "    return matching_words, len(matching_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d95f3b8f-4649-4cc3-8aed-2a48269adab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle cases where Tokens is not a string\n",
    "results = []\n",
    "\n",
    "for tokens in df['Tokens']:\n",
    "    # Check if tokens is a string; if not, convert to empty string\n",
    "    if isinstance(tokens, str):\n",
    "        tokens = tokens.lower().split()  # Lowercase and split by spaces\n",
    "    else:\n",
    "        tokens = []  # Treat non-strings (e.g., NaN or floats) as empty list\n",
    "\n",
    "    # Match tokens against combined_loan_types\n",
    "    matches, count = find_matches(tokens, unadapted_borrowings)\n",
    "    results.append({'Matching Words': matches, 'Count': count})\n",
    "\n",
    "# Add results to DataFrame\n",
    "df['matches'] = [result['Matching Words'] for result in results]\n",
    "df['match_count'] = [result['Count'] for result in results]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af0da0f2-e5ac-4773-88a5-871703febcf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 Tokens  \\\n",
      "0                            35 √•rig mand erkender drab   \n",
      "1     billedserie hjerteforeningens lokalkomite mang...   \n",
      "2                 det m√• jo v√¶re fraregnet lordbendtner   \n",
      "3     det er s√• godt , ! psykiatriske disgnoser skal...   \n",
      "4     n√∏ddesbos h√•nd i herning rundk√∏rsel jeg er en ...   \n",
      "...                                                 ...   \n",
      "1042  jeg sp√∏rger bare , hvorfor d√©t er i orden , n√•...   \n",
      "1043                                          s√• enig !   \n",
      "1044  men det var jo ret sjovt ) som ikke er ond mod...   \n",
      "1045  dat fejrer 30 √•r med fly det er i dag 30 √•r si...   \n",
      "1046  eriksen har en glimrende statistik mod city pl...   \n",
      "\n",
      "                                    matches  match_count  \n",
      "0                                        []            0  \n",
      "1                                     [for]            1  \n",
      "2                                        []            0  \n",
      "3                                   [,, en]            2  \n",
      "4                                [i, en, ,]            3  \n",
      "...                                     ...          ...  \n",
      "1042  [,, i, ,, i, af, i, en, podcast, dig]            9  \n",
      "1043                                     []            0  \n",
      "1044                                  [mod]            1  \n",
      "1045       [i, ,, og, i, de, over, og, end]            8  \n",
      "1046                        [en, mod, city]            3  \n",
      "\n",
      "[1047 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df[['Tokens', 'matches', 'match_count']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "446e2a0f-9a51-4ae8-b66b-6902d95dfa1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 Tokens    matches  \\\n",
      "0                            35 √•rig mand erkender drab         []   \n",
      "1     billedserie hjerteforeningens lokalkomite mang...         []   \n",
      "2                 det m√• jo v√¶re fraregnet lordbendtner         []   \n",
      "3     det er s√• godt , ! psykiatriske disgnoser skal...         []   \n",
      "4     n√∏ddesbos h√•nd i herning rundk√∏rsel jeg er en ...         []   \n",
      "...                                                 ...        ...   \n",
      "1042  jeg sp√∏rger bare , hvorfor d√©t er i orden , n√•...  [podcast]   \n",
      "1043                                          s√• enig !         []   \n",
      "1044  men det var jo ret sjovt ) som ikke er ond mod...         []   \n",
      "1045  dat fejrer 30 √•r med fly det er i dag 30 √•r si...         []   \n",
      "1046  eriksen har en glimrende statistik mod city pl...     [city]   \n",
      "\n",
      "      match_count  \n",
      "0               0  \n",
      "1               0  \n",
      "2               0  \n",
      "3               0  \n",
      "4               0  \n",
      "...           ...  \n",
      "1042            1  \n",
      "1043            0  \n",
      "1044            0  \n",
      "1045            0  \n",
      "1046            1  \n",
      "\n",
      "[1047 rows x 3 columns]\n",
      "           Match  Count\n",
      "0           plus     12\n",
      "1        handler     11\n",
      "2            bag     11\n",
      "3        problem     10\n",
      "4            set      9\n",
      "..           ...    ...\n",
      "280      culture      1\n",
      "281       travel      1\n",
      "282     longread      1\n",
      "283         star      1\n",
      "284  blackfacing      1\n",
      "\n",
      "[285 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# List of words to remove\n",
    "words_to_remove = {'e', 'I', 'm', 'k', 'b', 'a', 's', 'i', ',', 'en', 'for',  'og', 'de', 'af', 'et', 'man', 'her', 'da', 'over', 'end', 'have', 'mod', 'dig', 'alt', 'gang', 'to', 'igen', 'under', 'store', 'folk', 'g√•', 'dog'}\n",
    "\n",
    "# Remove unwanted words from the 'matches' column\n",
    "df['matches'] = df['matches'].apply(lambda match_list: [word for word in match_list if word.lower() not in words_to_remove])\n",
    "\n",
    "# Update the 'match_count' column with the new count after filtering\n",
    "df['match_count'] = df['matches'].apply(len)\n",
    "\n",
    "# Flatten the matches column into a single list for the summary table\n",
    "all_matches = [match for sublist in df['matches'] for match in sublist]\n",
    "\n",
    "# Create a frequency table (akin to R's table)\n",
    "match_counts = pd.Series(all_matches).value_counts()\n",
    "\n",
    "# Convert to a DataFrame for tabular output\n",
    "summary_table = match_counts.reset_index()\n",
    "summary_table.columns = ['Match', 'Count']\n",
    "\n",
    "# Display the updated DataFrame and summary table\n",
    "print(df[['Tokens', 'matches', 'match_count']])\n",
    "print(summary_table)\n",
    "\n",
    "# Total match count: 616\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "97f7f220-9368-4723-a10a-c6d6e0add7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving  \n",
    "\n",
    "df.to_csv('unadapted_borrowings_annotated.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 ",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
